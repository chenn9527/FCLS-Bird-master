# FCLS-Bird-master
By automatically detecting and classifying bird sounds, relevant researchers can learn ecological information about bird distribution, migration patterns, and habitat preferences. This paper proposes a bird sound classification method based on a lightweight model Feature fusion in bird sound Convolutional Neural Network (BS-CNN) and Long Short Term Memory(LSTM) with Support Vector Machine (SVM), abbreviated as FCLS. Among them, the BS-CNN integrates a self-attention module. Firstly, spectral subtraction is used to denoise the original sound data. The traditional double-threshold method struggles to extract segmented bird sound samples in their entirety. To address this problem, an improved double threshold method was designed to automatically extract segmented bird sounds from complex sound data. Then the sound features, Mel Frequency Cepstrum Coefficient (MFCC) and Gammatone Frequency Cepstrum Coefficient (GFCC), are extracted and fused as the fusion feature MGCC. Finally, the fused feature Mel-Gammatone frequency Cepstral Coefficients (MGCC) are input into the deep learning bird sound classification model to obtain the classification result. There are a total of 10 bird species and they were segmented into 10,480 audio samples by the improved double-threshold method. In order to verify the efficiency of the proposed model, FCLS was used to compare with 12 deep learning models and 4 traditional machine learning models based on the self-built bird sound dataset.

Our code is comming soon
