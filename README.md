# FCLS-Bird-master
By automatically detecting and classifying bird sounds, relevant researchers can learn ecological information about bird distribution, migration patterns, and habitat preferences. This paper proposes a bird sound classification method based on a lightweight model Feature fusion in Convolutional Neural Network (CNN) and Long Short Term Memory(LSTM) with Support Vector Machine (SVM), abbreviated as FCLS. Among them, the CNN integrates a self-attention module. Firstly, spectral subtraction is used to denoise the original sound data. Besides, the traditional double-threshold method struggles to extract segmented bird sound samples in their entirety. To address this problem, an improved double-threshold method was designed to automatically extract segmented bird sounds from complex sound data. Then the sound features, Mel Frequency Cepstrum Coefficient (MFCC) and Gammatone Frequency Cepstrum Coefficient (GFCC), are extracted and fused as the fusion feature MGCC. Finally, the fused feature Mel-Gammatone Frequency Cepstral Coefficients (MGCC) is input into the deep learning bird sound classification model to obtain the classification result. There are a total of 10 bird species and they were segmented into 10,480 audio samples by the improved double-threshold method. In order to verify the efficiency of the proposed model, the self-built dataset was used to compare with 12 deep learning models and 4 traditional machine learning models. The results verified the superiority of the FCLS.

Our code is comming soon
